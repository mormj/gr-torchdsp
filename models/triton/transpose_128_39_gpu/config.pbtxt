name: "transpose_128_39_gpu"
backend: "pytorch"
max_batch_size: 2
input [
  {
    name: "input__0"
    data_type: TYPE_FP32
    dims: [1, 9984]
  }
]
output [
  {
    name: "output__0"
    data_type: TYPE_FP32
    dims: [1, 9984 ]
  }
]

dynamic_batching {}

instance_group [
	{
		count: 1
		kind: KIND_GPU
	}
]
