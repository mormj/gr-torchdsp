id: torchdsp_triton_ofdm_divide_cc
label: Triton OFDM Divide
category: '[torchdsp]'

parameters:
- id: triton_url
  label: "Triton URL"
  dtype: string
  default: "localhost:8000"
- id: device
  label: "Device"
  dtype: enum
  options: [cpu, gpu]
  default: 'cpu'
- id: max_batch_size
  label: "Max Batch Size"
  dtype: int
  default: 256
- id: model_directory
  label: "Model Directory"
  dtype: string
  default: /tmp/rendered_triton_models
- id: fft_size_in
  label: "FFT In Size"
  dtype: int
  default: 64
- id: fft_size_out
  label: "FFT Out Size"
  dtype: int
  default: 128

inputs:
- label: in
  domain: stream
  dtype: complex
  vlen: ${fft_size_in}
  multiplicity: 2

outputs:
- label: out
  domain: stream
  dtype: complex
  vlen: ${fft_size_out}

file_format: 1

templates:
  imports: |- 
    import torchdsp
  make: |-
    <%
      import secrets
      import os
      tmp_modelname = secrets.token_hex(16)
      tmp_modelname_path = "\'" + os.path.join(model_directory, tmp_modelname).replace("'", "") + "\'"
    %>\
    None
    context = {"max_batch_size": ${max_batch_size}, "fft_size_in": ${fft_size_in}, "fft_size_out": ${fft_size_out}, "device": "${device}"}
    torchdsp.DynamicModels.render_model('ofdm_divide_cc', ${tmp_modelname_path}, context, ${triton_url})
    self.${id} = torchdsp.triton_block("${tmp_modelname}", ${max_batch_size}, ${triton_url}, [8*${fft_size_in}, 8*${fft_size_in}], [8*${fft_size_out}])